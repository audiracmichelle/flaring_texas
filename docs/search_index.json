[["index.html", "Flares Texas 1 Flares Texas", " Flares Texas Michelle Audirac 1 Flares Texas Previous studies have identified associations of negative health outcomes in populations within a circular radius from flaring events. A recent study provides evidence of adverse effects in all-cause mortality of elderly due to downwind-exposure to flaring. There is compounding evidence of the negative health effects of long term exposure to flaring pollution, both in the proximity and accounting for monthly prevailing wind direction. We compare the affected population according to three exposure metrics: 1) raw flaring-counts, 2) naive distance-weighted (kriging on centroid counts), 3) hyads. We don’t have a ground truth to compare estimates of exposure, so do the studies that use similar exposure metrics. Units of exposure are different for each metric. Exposure metrics are defined as follows. raw flaring-counts monthly flare concentrations are flaring counts per tract normalized by tract area. Average of monthly concentrations render year exposures per tract. naive distance-weighted kriging method is used to extrapolate exposure values in tracts within the spatial window that have zero flaring counts. This approach produces a proxy of distance weighted exposure to flares. To estimate monthly flare concentration surfaces, kriging values are obtained for monthly flare concentrations and are assigned to a 12sq km grid. Grid values are averaged over tracts. Average of monthly concentrations render year exposures per tract. hyads We look at exact trajectories and quantify the dispersion of air parcels within 12 hours from flaring sources. The focus is on the concentration of rapidly spreading air-parcels carrying airborne pollutants emitted during flaring. The exposure calculation takes parcel counts in 12 sq km grids. Monthly grid concentration values are averaged over tracts to obtain monthly concentrations which are then averaged to obtain year exposures per tract. Results are in terms of total exposed population. We present how much more population is affected when accounting for wind. Exposure is in different units, once “normalized to a density distribution”, population weighted measures are computed per basin (county/tract?). "],["preprocess-data.html", "2 Preprocess data", " 2 Preprocess data library(tidyverse) library(magrittr) library(lubridate) library(tidycensus) library(sf) library(maps) library(viridis) library(ggthemes) #### include your census api key #census_api_key(&#39;&lt;your_key&gt;&#39;, install = TRUE) #### read flares_raw data flares_data &lt;- read_csv(&quot;../data/input/tx-tracts-vnf-nightly.csv&quot;) flares_data %&lt;&gt;% mutate(STATEFP = as.character(STATEFP), #COUNTYFP = as.character(COUNTYFP), #TRACTCE = as.character(TRACTCE), GEOID = as.character(GEOID)) #### python code to download tracts shapefile from census-tiger site # import wget # from zipfile import ZipFile # import os # # url = &#39;https://www2.census.gov/geo/tiger/TIGER2016/TRACT/tl_2016_48_tract.zip&#39; # wget.download(url, os.path.expanduser(&#39;~/tmp&#39;)) # file_name = os.path.expanduser(&#39;~/tmp/tl_2016_48_tract.zip&#39;) # ZipFile(file_name, &#39;r&#39;).extractall(os.path.expanduser(&#39;~/tmp/tl_2016_48_tract/&#39;)) # os.system(&quot;ls ~/tmp/tl_2016_48_tract/&quot;) #### read administrative boundaries shapefiles state_sf &lt;- st_as_sf(maps::map(&quot;state&quot;, plot = FALSE, fill = TRUE)) %&gt;% filter(ID == &quot;texas&quot;) crs_ &lt;- st_crs(state_sf) tracts_sf &lt;- st_read(&quot;../data/input/tl_2016_48_tract/tl_2016_48_tract.shp&quot;) ## Reading layer `tl_2016_48_tract&#39; from data source ## `/Users/audiracmichelle/GitHub/audiracmichelle/flaring_texas/data/input/tl_2016_48_tract/tl_2016_48_tract.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 5265 features and 12 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -106.6456 ymin: 25.83716 xmax: -93.50804 ymax: 36.5007 ## Geodetic CRS: NAD83 tracts_sf &lt;- tracts_sf %&gt;% dplyr::filter(STATEFP == &quot;48&quot;) %&gt;% mutate(area = ALAND / 1e6) #ALAND in tiger filers is reported in sq meters tracts_sf &lt;- st_transform(tracts_sf, crs_) #### read National Oil and Gas Assessment Province Boundaries basins_sf &lt;- read_sf(&quot;../data/input/usprov12/usprov12.shp&quot;) %&gt;% rename(basin = PROVNAME) #class(st_geometry(basins_sf)) basins_sf %&lt;&gt;% st_transform(crs_) index &lt;- sapply(sf::st_intersects(basins_sf, tracts_sf), length) index &lt;- which(index &gt; 0) basins_sf &lt;- basins_sf[index, ] basins_sf %&gt;% ggplot() + geom_sf(data = state_sf) + geom_sf(aes(fill = basin), alpha = 0.5) # read low permeability oil and gas play boundaries play_bounds_sf &lt;- read_sf(&quot;../data/input/TightOil_ShaleGas_Plays_Lower48_EIA/ShalePlays_US_EIA_Dec2021.shp&quot;) play_bounds_sf %&lt;&gt;% st_transform(crs_) play_points_sf &lt;- play_bounds_sf %&gt;% st_make_valid() %&gt;% st_simplify() %&gt;% st_cast(&quot;MULTIPOINT&quot;) index &lt;- sapply(sf::st_intersects(play_points_sf, tracts_sf), length) index &lt;- which(index &gt; 0) play_bounds_sf &lt;- play_bounds_sf[index, ] ggplot() + geom_sf(data = state_sf) + geom_sf(data = play_bounds_sf, aes(col = Shale_play), fill = NA) #### get flares location (assuming they are located at tract-centroids) #### join flares_data with basins and flares locations flares_sf &lt;- tracts_sf %&gt;% filter(GEOID %in% unique(flares_data$GEOID)) flares_points_sf &lt;- st_centroid(flares_sf) coords &lt;- as_tibble(st_coordinates(flares_points_sf)) %&gt;% rename(Latitude = Y, Longitude = X) flares_sf &lt;- bind_cols(flares_sf, coords) index &lt;- unlist(sf::st_intersects(flares_points_sf, basins_sf)) flares_sf$basin &lt;- basins_sf$basin[index] flares_points_sf$basin &lt;- basins_sf$basin[index] flares_data %&lt;&gt;% left_join(flares_sf %&gt;% st_drop_geometry() %&gt;% select(GEOID, basin, Latitude, Longitude)) ggplot() + geom_sf(data = state_sf) + geom_sf(data = flares_sf, aes(fill = basin), alpha = 0.5) + geom_sf(data = flares_points_sf, aes(col = basin)) #### assign extent regions basins_sf$extent &lt;- basins_sf$basin basins_sf$extent[basins_sf$basin == &quot;South-Central New Mexico&quot;] &lt;- &quot;Permian Basin&quot; basins_sf$extent[basins_sf$basin == &quot;Palo Duro Basin&quot;] &lt;- &quot;Permian Basin&quot; basins_sf$extent[basins_sf$basin == &quot;Raton Basin-Sierra Grande Uplift&quot;] &lt;- &quot;Permian Basin&quot; basins_sf$extent[basins_sf$basin == &quot;Marathon Thrust Belt&quot;] &lt;- &quot;Permian Basin&quot; basins_sf$extent[basins_sf$basin == &quot;Arkoma Basin&quot;] &lt;- &quot;Bend Arch-Fort Worth Basin&quot; basins_sf$extent[basins_sf$basin == &quot;Southern Oklahoma&quot;] &lt;- &quot;Bend Arch-Fort Worth Basin&quot; basins_sf$extent[basins_sf$basin == &quot;Anadarko Basin&quot;] &lt;- &quot;Permian Basin&quot; #### join tracts_sf with basins and extent regions intr_list &lt;- sf::st_intersects(st_centroid(tracts_sf), basins_sf) intr_len &lt;- sapply(intr_list, length) # visual inspection # table(intr_len) # ggplot() + # geom_sf(data = state_sf) + # geom_sf(data = tracts_sf[which(intr_len == 0), ], col = &quot;blue&quot;) intr_list[which(intr_len == 0)] &lt;- 10 index &lt;- unlist(intr_list); rm(intr_list) tracts_sf$basin &lt;- basins_sf$basin[index] tracts_sf$extent &lt;- basins_sf$extent[index] basins_sf %&gt;% group_by(extent) %&gt;% summarise(geometry = st_union(geometry)) %&gt;% st_simplify(dTolerance = 5000) %&gt;% ggplot() + geom_sf(data = state_sf) + geom_sf(aes(fill = extent), alpha = 0.5) basins_sf %&gt;% filter(basin %in% c(&quot;Permian Basin&quot;, &quot;Bend Arch-Fort Worth Basin&quot;, &quot;Gulf Coast Basins&quot;)) %&gt;% ggplot() + geom_sf(aes(fill = extent), alpha = 0.5, size = 0) + geom_sf(data = state_sf, fill = NA) + geom_sf(data = flares_points_sf, size = 0.5) + geom_sf(data = play_bounds_sf, fill = NA, size = 1) + scale_fill_viridis_d() + theme_map() #### get tracts population v18 &lt;- load_variables(2018, &quot;acs5&quot;, cache = TRUE) # View(v18) # Estimate!!Total tract_acs &lt;- get_acs(year = 2018, geography = &quot;tract&quot;, variables = &quot;B01001_001&quot;, state = &quot;TX&quot;, geometry = FALSE) tract_acs %&lt;&gt;% rename(pop = estimate) #### join tracts and population # all shapefile GEOIDs in acs query # sum(!tracts_sf$GEOID %in% tract_acs$GEOID) tracts_sf %&lt;&gt;% left_join(tract_acs %&gt;% select(GEOID, pop)) #### recover area and population from tracts and add to flares data flares_data %&lt;&gt;% left_join( tracts_sf %&gt;% st_drop_geometry() %&gt;% select(GEOID, area, pop) ) #### disperseR input disperser_input &lt;- flares_data %&gt;% select(GEOID, date, flares, Latitude, Longitude) start_hour_ &lt;- lapply(1:nrow(disperser_input), function(x) seq(2, 22, 6)) disperser_input$start_hour = start_hour_ disperser_input &lt;- unnest(disperser_input, cols = c(start_hour)) disperser_input %&lt;&gt;% rename(ID = GEOID, start_day = date, w = flares) %&gt;% mutate(uID = ID, Height = 20, year = year(start_day), month = month(start_day), duration_emiss_hours = 1, duration_run_hours = 12) #### write rds files write_rds(flares_data, &quot;../data/preprocessed/flares_data.rds&quot;) write_rds(tracts_sf, &quot;../data/preprocessed/tracts_sf.rds&quot;) write_rds(disperser_input, &quot;../data/jobs_input/disperser_input.rds&quot;) "],["flares.html", "3 Flares", " 3 Flares library(tidyverse) library(magrittr) library(lubridate) library(knitr) library(sf) library(sp) library(cowplot) flares_data &lt;- read_rds(&quot;../data/preprocessed/flares_data.rds&quot;) tracts_sf &lt;- read_rds(&quot;../data/preprocessed/tracts_sf.rds&quot;) #there are flares for each year-month-basin, no need to fill zero values flares_data %&gt;% mutate(yyyy_mm = format(as.Date(date), &quot;%Y_%m&quot;)) %&gt;% group_by(yyyy_mm, basin) %&gt;% summarise(flares = sum(flares)) %&gt;% ggplot() + geom_line(aes(x = ym(yyyy_mm), y = flares, color = basin)) + theme_cowplot() + labs(title = &quot;Total flares per month&quot;, x = &quot;&quot;) ## `summarise()` has grouped output by &#39;yyyy_mm&#39;. You can override using the ## `.groups` argument. # tract-year-month entries are completed where zero is missing flares_months &lt;- flares_data %&gt;% mutate(year = year(date), month = month(date)) %&gt;% select(year, month, GEOID, basin, area, pop, flares) %&gt;% complete(nesting(year, month), nesting(GEOID, basin, area, pop), fill = list(flares = 0)) %&gt;% group_by(year, month, GEOID, basin, area, pop) %&gt;% summarise(flares = sum(flares, is.na = T)) %&gt;% ungroup() %&gt;% group_by(year, month) %&gt;% complete(GEOID) %&gt;% mutate(flares_area = flares / area) ## `summarise()` has grouped output by &#39;year&#39;, &#39;month&#39;, &#39;GEOID&#39;, &#39;basin&#39;, &#39;area&#39;. ## You can override using the `.groups` argument. #table(flares_months$GEOID) flares_years &lt;- flares_months %&gt;% group_by(year, GEOID, basin, area, pop) %&gt;% summarise( min_flares_area = min(flares_area, na.rm = T), q1_flares_area = quantile(flares_area, probs = 0.25, na.rm = T), median_flares_area = median(flares_area, na.rm = T), mu_flares_area = mean(flares_area, na.rm = T), q3_flares_area = quantile(flares_area, probs = 0.75, na.rm = T), max_flares_area = max(flares_area, na.rm = T) ) ## `summarise()` has grouped output by &#39;year&#39;, &#39;GEOID&#39;, &#39;basin&#39;, &#39;area&#39;. You can ## override using the `.groups` argument. ggplot(flares_years) + geom_boxplot(aes(x = as.factor(year), y = mu_flares_area, col = basin)) + labs(title = &quot;Mean of monthly flares per sq km (for tracts with flares)&quot;) time_parquet_sf &lt;- tracts_sf %&gt;% filter(GEOID %in% unique(flares_data$GEOID), basin == &quot;Permian Basin&quot;) %&gt;% select(GEOID) time_parquet_sf %&lt;&gt;% left_join( flares_years %&gt;% pivot_wider(id_cols = GEOID, names_from = year, values_from = mu_flares_area) ) %&gt;% select(-GEOID) ## Joining, by = &quot;GEOID&quot; spplot(as_Spatial(time_parquet_sf)) time_parquet_sf &lt;- tracts_sf %&gt;% filter(GEOID %in% unique(flares_data$GEOID), basin == &quot;Gulf Coast Basins&quot;) %&gt;% select(GEOID) time_parquet_sf %&lt;&gt;% left_join( flares_years %&gt;% pivot_wider(id_cols = GEOID, names_from = year, values_from = mu_flares_area) ) %&gt;% select(-GEOID) ## Joining, by = &quot;GEOID&quot; spplot(as_Spatial(time_parquet_sf)) flares_years %&gt;% ggplot() + geom_point(aes(x = mu_flares_area, y = pop)) + facet_wrap(~year) + labs(title = &quot;population vs mean of monthly flares per sq km&quot;) top_rank_area &lt;- flares_years %&gt;% arrange(basin, year, desc(mu_flares_area)) %&gt;% group_by(year, basin) %&gt;% mutate(rank = row_number()) %&gt;% slice(1:3) top_rank_area %&gt;% DT::datatable() "],["parcels-checkpoint.html", "4 Parcels checkpoint 4.1 check 1 4.2 check 2 4.3 check 3 4.4 check 4", " 4 Parcels checkpoint source(&quot;../lib/polygon_parcels_parallel.R&quot;) library(tidyverse) library(magrittr) library(lubridate) library(data.table) library(fst) library(sf) library(gridExtra) library(cowplot) library(viridis) library(ggthemes) library(knitr) disperser_input &lt;- read_rds(&quot;../data/jobs_input/disperser_input.rds&quot;) polygons_sf &lt;- st_read(&quot;../data/input/tl_2016_48_tract/tl_2016_48_tract.shp&quot;) # &lt;- for polygon_parcel input ## Reading layer `tl_2016_48_tract&#39; from data source ## `/Users/audiracmichelle/GitHub/audiracmichelle/flaring_texas/data/input/tl_2016_48_tract/tl_2016_48_tract.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 5265 features and 12 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -106.6456 ymin: 25.83716 xmax: -93.50804 ymax: 36.5007 ## Geodetic CRS: NAD83 tracts_sf &lt;- read_rds(&quot;../data/preprocessed/tracts_sf.rds&quot;) # &lt;- for analysis 4.1 check 1 check disperser was able to run simulations for all emissions in disperser_input (compare with ls | wc at the simulations location) #### number of files disperser will create for each year month disperser_input %&gt;% group_by(year, month) %&gt;% summarise(n = n()) %&gt;% DT::datatable() ## `summarise()` has grouped output by &#39;year&#39;. You can override using the ## `.groups` argument. 4.2 check 2 validate that the number of parcels that are dispersed in each simulation run are counted in the polygon_parcel function #### set params for run_polygon_parcels polygons_sf %&lt;&gt;% filter(STATEFP == &quot;48&quot;) %&gt;% mutate(GEOID = as.character(GEOID)) %&gt;% rename(id = GEOID) polygons_sf &lt;- polygons_sf[, &#39;id&#39;] hysp_dir = &quot;../data/jobs_output/vanilla/hysplit&quot; mc.cores = parallel::detectCores() range = which(disperser_input$start_day == as.Date(&quot;2018-01-06&quot;) &amp; disperser_input$start_hour == 2) input.refs = data.table(disperser_input[range,], stringsAsFactors = FALSE) run_X &lt;- lapply(1:nrow(input.refs), function(r) input.refs[r]) res.link = 12000 polygon_parcels &lt;- list() parcels_count &lt;- c() plots &lt;- list() for(X in run_X){ polygon_parcels_ &lt;- run_polygon_parcels(X = X, polygons_sf = polygons_sf, hysp_dir = hysp_dir, res.link = res.link) r &lt;- polygon_parcels_[[1]] polygon_parcels[[X$ID]] &lt;- polygon_parcels_[[2]] parcels_count &lt;- c(parcels_count, sum(polygon_parcels[[X$ID]]$count, na.rm = T)) parcels_sf &lt;- tracts_sf %&gt;% left_join(rename(polygon_parcels[[X$ID]], GEOID = id)) %&gt;% filter(GEOID %in% polygon_parcels[[X$ID]]$id) %&gt;% mutate(concentration = count / area) p1 &lt;- ggplot(parcels_sf) + geom_sf(aes(fill = count), size = 0) + geom_sf(data = (filter(parcels_sf, GEOID == X$ID)), color = &quot;red&quot;, fill = NA) + scale_fill_viridis(option = &quot;B&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) p2 &lt;- ggplot(parcels_sf) + geom_sf(aes(fill = concentration), size = 0) + geom_sf(data = (filter(parcels_sf, GEOID == X$ID)), color = &quot;red&quot;, fill = NA) + scale_fill_viridis(option = &quot;B&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) p3 &lt;- ggplot(parcels_sf) + geom_sf(aes(fill = hyads), size = 0) + geom_sf(data = (filter(parcels_sf, GEOID == X$ID)), color = &quot;red&quot;, fill = NA) + scale_fill_viridis(option = &quot;B&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) p4 &lt;- ggplot(parcels_sf) + geom_sf() + geom_sf(data = (filter(parcels_sf, GEOID == X$ID)), color = &quot;red&quot;, fill = NA) + geom_sf(data = st_as_sf(r), aes(fill = layer), alpha = 0.8, color = &quot;white&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) # p4 &lt;- parcels_sf %&gt;% # mutate(concentr_adj = concentration / max(parcels_sf$concentration, na.rm = T), # hyads_adj = hyads / max(parcels_sf$hyads, na.rm = T)) %&gt;% # ggplot() + # geom_point(aes(x=hyads_adj, y=count)) + # geom_point(aes(x=concentr_adj, y=count), col = &quot;red&quot;) + # labs(x = &quot;concentration (red), hyads(black)&quot;) plots[[X$ID]] &lt;- plot_grid(p1, p2, p4, p3) } polygon_parcels_1 &lt;- rbindlist(polygon_parcels) #grid square base sqrt(as.numeric(st_area(st_as_sf(r)[1, ])) / 1e6) ## [1] 12 parcels_count ## [1] 1200 1200 1200 1200 1200 1200 1200 1200 1200 1200 1200 1200 1200 1200 1200 ## [16] 1200 1200 1200 1200 1200 1200 1200 1200 1200 1200 1200 4.3 check 3 visual inspection of counts and raw concentrations and exposure estimates using two values for res.link the length of the grid square’s sides that are used to compute hyads exposure. The first group uses res.link=12000 and the second group res.link=50000. 4.3.1 Group 1 Hyads smothes the parcel dispersion and assigns an exposure measure. With res.link=12000 the exposure looks good. plots[c(1, 5, 22, 23)] ## $`48235950100` ## ## $`48013960600` ## ## $`48149970600` ## ## $`48283950300` Sometimes it is not obvious how the daily exposure estimation is smooth. plots[c(11, 12, 14, 18)] ## $`48495950400` ## ## $`48173950100` ## ## $`48507950301` ## ## $`48165950200` 4.3.2 Group 2 Parameter tuning of grid resolution must balance between grid’s square sizes, polygon sizes and sparsity (number of simulated parcels). res.link = 50000 polygon_parcels &lt;- list() parcels_count &lt;- c() plots &lt;- list() for(X in run_X){ polygon_parcels_ &lt;- run_polygon_parcels(X = X, polygons_sf = polygons_sf, hysp_dir = hysp_dir, res.link = res.link) r &lt;- polygon_parcels_[[1]] polygon_parcels[[X$ID]] &lt;- polygon_parcels_[[2]] parcels_count &lt;- c(parcels_count, sum(polygon_parcels[[X$ID]]$count, na.rm = T)) parcels_sf &lt;- tracts_sf %&gt;% left_join(rename(polygon_parcels[[X$ID]], GEOID = id)) %&gt;% filter(GEOID %in% polygon_parcels[[X$ID]]$id) %&gt;% mutate(concentration = count / area) p1 &lt;- ggplot(parcels_sf) + geom_sf(aes(fill = count), size = 0) + geom_sf(data = (filter(parcels_sf, GEOID == X$ID)), color = &quot;red&quot;, fill = NA) + scale_fill_viridis(option = &quot;B&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) p2 &lt;- ggplot(parcels_sf) + geom_sf(aes(fill = concentration), size = 0) + geom_sf(data = (filter(parcels_sf, GEOID == X$ID)), color = &quot;red&quot;, fill = NA) + scale_fill_viridis(option = &quot;B&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) p3 &lt;- ggplot(parcels_sf) + geom_sf(aes(fill = hyads), size = 0) + geom_sf(data = (filter(parcels_sf, GEOID == X$ID)), color = &quot;red&quot;, fill = NA) + scale_fill_viridis(option = &quot;B&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) p4 &lt;- ggplot(parcels_sf) + geom_sf() + geom_sf(data = (filter(parcels_sf, GEOID == X$ID)), color = &quot;red&quot;, fill = NA) + geom_sf(data = st_as_sf(r), aes(fill = layer), alpha = 0.8, color = &quot;white&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) # p4 &lt;- parcels_sf %&gt;% # mutate(concentr_adj = concentration / max(parcels_sf$concentration, na.rm = T), # hyads_adj = hyads / max(parcels_sf$hyads, na.rm = T)) %&gt;% # ggplot() + # geom_point(aes(x=hyads_adj, y=count)) + # geom_point(aes(x=concentr_adj, y=count), col = &quot;red&quot;) + # labs(x = &quot;concentration (red), hyads(black)&quot;) plots[[X$ID]] &lt;- plot_grid(p1, p2, p4, p3) } polygon_parcels_2 &lt;- rbindlist(polygon_parcels) #grid square base sqrt(as.numeric(st_area(st_as_sf(r)[1, ])) / 1e6) ## [1] 50 plots[c(1, 5, 22, 23)] ## $`48235950100` ## ## $`48013960600` ## ## $`48149970600` ## ## $`48283950300` plots[c(11, 12, 14, 18)] ## $`48495950400` ## ## $`48173950100` ## ## $`48507950301` ## ## $`48165950200` 4.4 check 4 inspection of counts of parcels from all locations, its concentration, and hyads exposure in a single day. Group 1 and 2 use different grid resolutions, res.link=12000 and res.link=50000. Exposure estimates change with grid resolution. flares_sf &lt;- tracts_sf %&gt;% left_join(rename(input.refs, GEOID = ID)) %&gt;% filter(GEOID %in% disperser_input$ID) p1 &lt;- flares_sf %&gt;% ggplot() + geom_sf(aes(fill = w), size = 0) + scale_fill_viridis(option = &quot;B&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) polygon_parcels &lt;- polygon_parcels_1 polygon_parcels %&lt;&gt;% group_by(id, w, source) %&gt;% summarise(count = w * sum(count, na.rm = T), hyads = w * hyads) parcels_sf &lt;- tracts_sf %&gt;% left_join(rename(polygon_parcels, GEOID = id)) %&gt;% filter(GEOID %in% polygon_parcels$id) %&gt;% mutate(concentration = w * count / area) p2 &lt;- parcels_sf %&gt;% ggplot() + geom_sf(aes(fill = count), size = 0) + scale_fill_viridis(option = &quot;B&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) p3 &lt;- parcels_sf %&gt;% ggplot() + geom_sf(aes(fill = concentration), size = 0) + scale_fill_viridis(option = &quot;B&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) p4 &lt;- parcels_sf %&gt;% ggplot() + geom_sf(aes(fill = hyads), size = 0) + scale_fill_viridis(option = &quot;B&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) polygon_parcels &lt;- polygon_parcels_2 polygon_parcels %&lt;&gt;% group_by(id, w, source) %&gt;% summarise(count = w * sum(count, na.rm = T), hyads = w * hyads) parcels_sf &lt;- tracts_sf %&gt;% left_join(rename(polygon_parcels, GEOID = id)) %&gt;% filter(GEOID %in% polygon_parcels$id) %&gt;% mutate(concentration = w * count / area) p5 &lt;- parcels_sf %&gt;% ggplot() + geom_sf(aes(fill = hyads), size = 0) + scale_fill_viridis(option = &quot;B&quot;) + theme_map() + theme(legend.position = &quot;none&quot;) plot_grid(p1, p2, p3, p4, p5) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
